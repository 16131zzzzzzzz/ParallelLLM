"""
测试目标: OpenAI Provider基本功能测试
- 测试OpenAI提供商的聊天和embedding功能
- 测试请求格式转换和响应处理
- 测试错误处理机制
- 使用Mock API调用，不需要真实API密钥
- 简化版Provider测试，快速验证核心功能
"""
import unittest
from unittest.mock import AsyncMock, patch
import asyncio
import os
import sys
import tempfile

# 添加项目根目录和tests目录到Python路径
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
sys.path.insert(0, os.path.dirname(__file__))

from conftest import TestConfig, mock_chat_response, mock_embedding_response
from pllm import Client


class TestOpenAIProvider(unittest.IsolatedAsyncioTestCase):
    """OpenAI提供商测试"""
    
    async def asyncSetUp(self):
        """测试初始化"""
        self.temp_dir = tempfile.TemporaryDirectory()
        self.config = {
            "llm": {
                "use": "openai",
                "openai": [
                    {
                        "api_key": "sk-mock-openai-key",
                        "api_base": "https://api.openai.com/v1",
                        "model": "gpt-4o-mini",
                        "rate_limit": 10
                    }
                ]
            }
        }
        self.config_path = TestConfig.write_temp_config(self.config)
        self.client = Client(self.config_path)
        
        # 不启动健康检查任务，避免测试挂起
        # 健康检查在单元测试中不是必需的
    
    async def asyncTearDown(self):
        """测试清理"""
        # 清理资源
        self.temp_dir.cleanup()
        if os.path.exists(self.config_path):
            os.unlink(self.config_path)
    
    @patch("pllm.providers.openai_provider.AsyncOpenAI")
    async def test_chat(self, mock_openai_class):
        """测试聊天功能"""
        # Mock the OpenAI client and its methods
        mock_client = AsyncMock()
        mock_openai_class.return_value = mock_client
        
        # Mock response structure to match OpenAI's response format
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = "Hello from OpenAI"
        mock_response.usage.prompt_tokens = 5
        mock_response.usage.completion_tokens = 5
        mock_response.usage.total_tokens = 10
        mock_response.model_dump.return_value = {"test": "response"}
        
        mock_client.chat.completions.create.return_value = mock_response
        
        messages = [{"role": "user", "content": "Hello"}]
        response = await self.client.chat(messages)
        
        self.assertIsInstance(response, str)
        self.assertEqual(response, "Hello from OpenAI")
        mock_client.chat.completions.create.assert_called_once()
    
    @patch("pllm.providers.openai_provider.AsyncOpenAI")
    async def test_generate(self, mock_openai_class):
        """测试生成功能"""
        # Mock the OpenAI client and its methods
        mock_client = AsyncMock()
        mock_openai_class.return_value = mock_client
        
        # Mock response structure
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = "Generated by OpenAI"
        mock_response.usage.prompt_tokens = 5
        mock_response.usage.completion_tokens = 5
        mock_response.usage.total_tokens = 10
        mock_response.model_dump.return_value = {"test": "response"}
        
        mock_client.chat.completions.create.return_value = mock_response
        
        response = await self.client.generate("Tell me a joke")
        
        self.assertIsInstance(response, str)
        self.assertEqual(response, "Generated by OpenAI")
        mock_client.chat.completions.create.assert_called_once()
    
    @patch("pllm.providers.openai_provider.AsyncOpenAI")
    async def test_embedding(self, mock_openai_class):
        """测试embedding功能"""
        # Mock the OpenAI client and its methods
        mock_client = AsyncMock()
        mock_openai_class.return_value = mock_client
        
        # Mock embedding response structure
        mock_response = AsyncMock()
        mock_response.data = [AsyncMock()]
        mock_response.data[0].embedding = [0.1] * 384
        mock_response.usage.total_tokens = 5
        mock_response.model_dump.return_value = {"test": "embedding_response"}
        
        mock_client.embeddings.create.return_value = mock_response
        
        response = await self.client.embedding("test text")
        
        self.assertIsInstance(response, list)
        self.assertTrue(len(response) > 0)
        self.assertIsInstance(response[0], float)
        mock_client.embeddings.create.assert_called_once()
    
    def test_sync_methods(self):
        """测试同步方法"""
        with patch.object(self.client, 'generate', new_callable=AsyncMock) as mock_generate:
            mock_generate.return_value = "Sync response from OpenAI"
            result = self.client.generate_sync("test prompt")
            self.assertEqual(result, "Sync response from OpenAI")
        
        with patch.object(self.client, 'chat', new_callable=AsyncMock) as mock_chat:
            mock_chat.return_value = "Sync chat from OpenAI"
            result = self.client.chat_sync([{"role": "user", "content": "hi"}])
            self.assertEqual(result, "Sync chat from OpenAI")
    
    def test_stats_tracking(self):
        """测试统计信息跟踪"""
        stats = self.client.get_stats()
        self.assertIsInstance(stats, dict)
        
        if "openai" in stats:
            provider_stats = stats["openai"]
            self.assertIsInstance(provider_stats, list)
            
            for client_stat in provider_stats:
                self.assertIn("total_requests", client_stat)
                self.assertIn("total_tokens", client_stat)
                self.assertIn("error_count", client_stat)
                self.assertIn("active", client_stat)


if __name__ == "__main__":
    unittest.main()